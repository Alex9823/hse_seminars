{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hidden Markov Models\n",
    "\n",
    "Outline:\n",
    "1. Markov model\n",
    "1. State transition matrix\n",
    "1. Maximum likelihood parameter assignment\n",
    "1. Hidden Markov Model\n",
    "1. Probability of observed sequence\n",
    "1. Viterbi algorithms\n",
    "\n",
    "\n",
    "## Example\n",
    "\n",
    "<img src=images/hmm1.png height=400/>\n",
    "\n",
    "\n",
    "Hidden states = {rainy, sunny}\n",
    "observables = {walk, shop, clean}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "e33df193-df05-4686-9b96-1e44b72ff893"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1. Markov model\n",
    "\n",
    "Given set of states $S = \\{s_1, ..., s_m\\}$ we observe series over time $x = \\{x_1, ..., x_T\\}$, $x \\in S^T$\n",
    "\n",
    "Assumptions about markov model:\n",
    "* Limited horizon  \n",
    "$P(x_t | x_{t-1}, x_{t-2}, ..., x_{t-n}) = P(x_{t} | x_{t-1})$\n",
    "\n",
    "* Stationary process  \n",
    "$P(x_{t} | x_{t-1}) = P(x_2 | x_1)$ for $t \\in 2..T$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 State transition matrix \n",
    "\n",
    "State transition matrix $A \\in R^{|S| x |S|}$, where  \n",
    "$A_{ij}$ is probabilty of transition from state $s_i$ to state $s_j$\n",
    "\n",
    "We compute probability of the particular sequence x by chain rule using limited horizon assumption:  \n",
    "$$P(x_T, x_{T-1}, x_{T-2}, ..., x_1; A) = \\\\\n",
    "= P(x_T | x_{T-1}, ..., x_0; A)P(x_{T-1} | x_{T-2}, ..., x_0; A)...P(x_1 | x_0; A)P(x_0;A)\\\\ \n",
    " =P(x_{T} | x_{T-1}; A) P(x_{T-1} | x_{T-2}; A) P(x_2 | x_1; A) P(x_1 | x_0; A) = \\\\ = \\prod_{T=1}^T P(x_{T} | x_{T-1}; A) = \\prod_{T=1}^T A_{x_{T-1}, x_t}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "45da01de-772c-4f72-80dd-04fb6cc3947c"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3 Maximum likelihood parameter assignment\n",
    "\n",
    "$$Likelihood(A) = log P(z; A) = \\\\ \n",
    "= log \\prod_{t=1}^T A_{z_{t-1}, z_t} = \\sum_{t=1}^T log A_{z_{t-1}, z_t} = \\\\ \n",
    "= \\sum_{t=1}^T \\sum_{i=1}^{|S|} \\sum_{j=1}^{|S|} [z_{t-1} = s_i \\wedge z_t = s_j]log A_{ij}$$\n",
    "\n",
    "We want:  \n",
    "* $l(A) \\rightarrow \\underset {A} {\\max}$  \n",
    "* $\\sum_{j=1}^{|S|} A_{ij} = 1 $  \n",
    "* $A_{ij} \\geq 0$  \n",
    "\n",
    "With Lagrange multipliers we can get following estimate:  \n",
    "$$\\hat A_{ij} = \\frac {\\sum_{t=1}^T  [z_{t-1} = s_i \\wedge z_t = s_j]} {\\sum_{t=1}^T  [z_{t-1} = s_i]}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "07099aa9-36f0-49b3-b5a8-bd1e3b2adfc0"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4 Hidden Markov Model\n",
    "\n",
    "<img src=images/hmm2.png height=400/>\n",
    "\n",
    "Let   \n",
    "$S$ - set of hidden states  \n",
    "$O$ - set of observables  \n",
    "$x_t \\in S$ - hidden variables  \n",
    "$y_t \\in O$ - observed variables  \n",
    "$A \\in R^{|S|x|S|}$ - transition matrix  \n",
    "$B \\in R^{|S|x|O|}$ - emition matrix  \n",
    "\n",
    "Probability of sequence of observed states:\n",
    "\n",
    "$$P(y; A, B) = \\sum_{x_0, .., x_T} P(y, x; A, B) = \\sum_{x_0, .., x_T} P(y|x; A, B) P(x; A, B) = \\\\ \n",
    "= \\sum_{x_0, .., x_T} ( \\prod_{t=1}^T P(y_t|x_t; B) ) ( \\prod_{t=1}^T P(x_t|x_{t-1}; A) ) = \\\\ \n",
    "= \\sum_{x_0, .., x_T} ( \\prod_{t=1}^T B_{x_t, y_t} ) ( \\prod_{t=1}^T A_{x_{t-1}, x_t} )$$  \n",
    "\n",
    "\n",
    "Evaluating the prob directly costs $O(|S|^T)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "31a1293e-8865-425b-9a3f-9ebc92493c34"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Fundamental questions for HMM:\n",
    "* What is the probability of the observed sequence?  \n",
    "Given HMM (A, B) and observations x, caclulate probability that HMM generated x.\n",
    "* What is the most likely series of states to generate the observations?  \n",
    "Given HMM (A, B) and observations x, caclulate the most likely sequence of hidden states, that produced observations x.  \n",
    "* How can we learn A and B?  \n",
    "Given some training observations x and general structure of HMM (number of hidden and visible states), determine (A, B) that best fit the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "239c31c1-a42c-4e6e-93e0-ccd7ce66a243"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  5 Probability of observed sequence\n",
    "\n",
    "###Forward algorithm \n",
    "for computing for computing probability of observed sequence:\n",
    "\n",
    "Define $$\\alpha_i(t) = P(y_1, y_2, ..., y_t, x_t=s_i; A, B)$$ - total probability of all observations up through time t, and being at state s_i at time t.  \n",
    "Then,  \n",
    "$$P(x; A, B) = P(y_1, ..., y_T; A, B) = \\sum_{i=1}^{|S|} P(y_1, ..., y_T, x_T = s_i; A, B)) = \\sum_{i=1}^{|S|} \\alpha_i(T)$$\n",
    "\n",
    "We can compute with for $O(|S| T)$ by dynamic programming:  \n",
    "$\\alpha_i (0) = A_{0, i} $  \n",
    "$\\alpha_j (t) = \\sum_{i=1}^{|S|} \\alpha_i (t-1) A_{ij} B_{j, y_t} $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "07ffd16b-95f4-4ea7-af7a-fe7b3f939b04"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 6 Viterbi algorithm  \n",
    "\n",
    "For maximum likelihood state assignment. \n",
    "\n",
    "Given series of outputs $y \\in O^T$:  \n",
    "\n",
    "$$arg max_x P(x|y; A, B) = arg max_x \\frac {P(y, x; A, B)} {\\sum_x P(y, x; A, B)} = arg max_x P(y, x; A, B)$$\n",
    "\n",
    "Naive approach in $O(|S|^T)$.  \n",
    "\n",
    "Let $\\pi[j, s]$ - max probability for any state sequence ending in state $s$ at position $t=j$.\n",
    "\n",
    "$$\\pi[1, s] = A_{0, s} B_{s, y_1}$$\n",
    "\n",
    "$$\\pi[j, s] = max_{i \\in {1 .. k}} \\pi[j-1, i] A_{i, s} B_{s, y_j}$$\n",
    "$$bp[j, s] = arg max_{i \\in {1 .. k}} \\pi[j-1, i] A_{i, s} B_{s, y_j}$$\n",
    "\n",
    "Recover all sequence:  \n",
    "$$s_T = argmax_s \\pi[T, s]$$  \n",
    "$$s_{j-1} = bp[j, s_j]$$\n",
    "\n",
    "Complexity $O(T |S|^2)$"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
